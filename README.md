# ğŸ§  SQL Data Warehouse Project (ETL + Modeling + Architecture)

Welcome to my SQL Data Warehouse Project! ğŸš€
This repository showcases a full end-to-end Data Warehouse built from scratch â€” including ETL development, data modeling, architecture design, and clean repository structuring.

The project is designed as a practical portfolio piece to demonstrate real-world data engineering practices using only SQL Server.


---

# ğŸ— Medallion Data Architecture

This Data Warehouse follows the Medallion Architecture, organizing data into three structured layers:

![High-Level Architecture](docs/data_architecture.png)
---

## 1. Bronze Layer â€“ Raw Data Ingestion

- Ingests and stores raw data as-is from source systems (CRM & ERP) into the SQL Server database using automated load scripts.


## 2. Silver Layer â€“ Transformation & Standardization

- Cleans, standardizes, normalizes and enriches data to ensure consistency and quality.
- Applies business rules and validation logic, with error handling & logging for ETL monitoring 
  

## 3. Gold Layer â€“ Business-Ready Data Model

- Builds fact and dimension tables following a star schema
- Produces business-ready, analytics-ready datasets optimized for reporting  

---

# âš™ï¸ Project Overview
1. **Data Architecture**: Designing a modern Data Warehouse using the Medallion architecture with **Bronze, Silver** and **Gold** layers.
2. **ETL Pipeline**: Implementing an end-to-end ETL pipeline to extract, transform and load data from source systems into the arehouse
3. **Data Modeling**: Building fact and dimension tables optimized for analytical queries & reporting

---

# ğŸ“ Repository Structure


SQL-Data-Warehouse-Project/ â”œâ”€ Datasets/ â”‚  â”œâ”€ source_crm/ â”‚  â”‚  â”œâ”€ cst_ifo.csv           # Customer information from CRM â”‚  â”‚  â”œâ”€ prd_ifo.csv           # Product information from CRM â”‚  â”‚  â””â”€ sales_details.csv     # Sales transactions from CRM â”‚  â””â”€ source_erp/ â”‚     â”œâ”€ CUST-AZ12             # ERP Customer data â”‚     â”œâ”€ LOC_A101              # ERP Location data â”‚     â””â”€ PX_CAT_G1V2           # ERP Product Category data â”œâ”€ Docs/ â”‚  â”œâ”€ Data_architecture.png    # High-level architecture diagram â”‚  â”œâ”€ Data_catalog.md          # Data dictionary & catalog â”‚  â”œâ”€ Data_flow.png            # ETL / data flow diagram â”‚  â””â”€ Data_model.pbg           # Star schema / data model diagram â”œâ”€ Scripts/ â”‚  â”œâ”€ Bronze/ â”‚  â”‚  â”œâ”€ ddl_bronze/          # Bronze layer table definitions â”‚  â”‚  â””â”€ proc_load_bronze/    # Stored procedures to load raw data â”‚  â”œâ”€ Silver/ â”‚  â”‚  â”œâ”€ ddl_silver/          # Silver layer table definitions â”‚  â”‚  â””â”€ proc_load_silver/    # Stored procedures for data transformation â”‚  â””â”€ Gold/ â”‚     â””â”€ ddl_gold/             # Gold layer table definitions (fact & dimension tables) â”œâ”€ Test/ â”‚  â”œâ”€ Quality_checks_silver/   # Data quality checks for Silver layer â”‚  â””â”€ Quality_checks_gold/     # Data quality checks for Gold layer â””â”€ README.md                   # Project overview & documentation

--------------------------

# ğŸ§° Tools & Technologies

- SQL Server â€“ Database platform and ETL execution  
- T-SQL Stored Procedures â€“ Data transformation logic  
- draw.io â€“ Architecture and data modeling diagrams  
- CSV / Excel â€“ Source data files  
- GitHub â€“ Version control and project documentation  

---

# ğŸ”® Future Improvements

This project will be re-implemented using:

- Python â€“ For ETL transformations and data manipulation  
- Apache Airflow â€“ To automate and orchestrate ETL pipelines  

The goal is to build a fully orchestrated, automated modern data pipeline with better scheduling, monitoring, and scalability.
